# Дипломный проект: Обучение языковой модели для предсказания выходов биохимических реакций

Целью проекта было дообучить llm с помощью LoRA для предсказания класса выхода органической реакции, где high - выход >= 70% и low - выход < 70%

## Актуальность проекта

В процессе производства всегда необходимо знать выход продукта той или иной реакции. Каждый раз узнавать экспериментально выход продукта не только времязатратно, но и требует большого количества ресурсов. Обучение предиктивной языковой модели позволит получить алгоритм, предсказывающий выходы органических реакций с должной точностью, не замедляя при этом исследование или производство и не создавая дополнительных трат.  

Опубликованные предиктивные модели сфокусированы на узких классах реакций либо показывают низкую точность.  

Таким образом, проектирование полноценной языковой модели было бы актуально для биотехнологического/химического/фармацевтического производства

## Структура репозитория

Проект состоит из последовательности скриптов и notebook'ов:

1. `1_data_preparation.ipynb` - подготовка и первичная обработка данных, анализ данных, подготовка словаря с уникальными молекулами
2. `2_dict_SMILES_text.py` - создание словаря формата ключ - химическое вещество в формате SMILES, значение - название вещества на английском языке по номенклатуре ИЮПАК
3. `3_data_from_SMILES_to_text.ipynb` - преобразование реакций с SMILES-моелкулами в текстовый формат
4. `4_train_test_splitting.ipynb` - формирование тренировочного и тестового датасетов с включенными few-shot промптами
5. `5_llama_training.py` - обучение модели Reasoning LLaMA v0.1 1B
6. `6_inference.py` - инференс обученной модели
7. `7_metrics.ipynb` - расчет метрик качества модели

На Google-диске лежат все наборы данных (т.к. в GitHub нельзя загружать такие большие файлы), а также продублированный код проекта: https://drive.google.com/drive/folders/1aluuIDcfMWWDgcMjaZm31yGXYTW1L38m  

С кратким описанием проекта можно ознакомиться в презентации: https://docs.google.com/presentation/d/127748ypiFPfdWrKSh2JePjsx2wxyzDcQ/edit?usp=sharing&ouid=112718877929397810155&rtpof=true&sd=true

Подробное описание проекта можно найти в документе моего диплома: https://docs.google.com/document/d/18k6BVzBbitiNnUuOjswuUi0GdIbfU60ci3ddHfYMxeM/edit?usp=sharing

Выбор модели (итог - Reasoning Llama v0.1 1B) и формата промпта (итог - few-shots) был осуществлен экспериментально. 20 случайно выбранных реакций из датасета прогонялись через отобранные модели (модели отбирались по новизне и небольшому количеству параметров), а также прогонялись через лучшие модели с различными формулировками промптов. Результаты экспериментов были записаны в таблицу: https://docs.google.com/spreadsheets/d/1zGEa4tiJ6lQfgJxAZhLvIxbawqEFmnze18G4R2nrink/edit?gid=0#gid=0 

Пример:
![image](https://github.com/user-attachments/assets/73ed615b-3a3e-499f-b3f7-510f5f7ea707)

Внутри файлов проекта находятся подробные инструкции "что и для чего делается". Для ознакомления с проектом рекомендуется пройти по каждому из файлов последовательно в порядке их нумерации.

## Результаты  

Accuracy: 0.653  
Precision: 0.662  
Recall: 0.701  
F1-score: 0.681  

Обучена языковая модель, способная с определенной точностью предсказывать класс выхода органической реакции  
Создан набор данных с 1549152 уникальными органическими молекулами, где для каждой молекулы в формате SMILES есть наименование молекулы по номенклатуре ИЮПАК на английском языке  
Готов полный пайплайн проекта и валидный код для улучшения проекта или создания нового проекта с новой целью  

В дальнейшем я планирую развивать данный проект.

Изменения, которые я бы хотел привнести для улучшения проекта:
- Опробовать другие модели, хорошо показавшие себя при отборе
- Оставить метод few-shot в промптах, но убрать формат чата, для облегчения понимания задания
- Расширить датасет путем добавления новых фич для реакций (физико-химические свойства веществ, условия реакций и т.п.)
- Предобучить модель на химических данных для понимания контекста
- Дообучить модель для предсказания численного выхода реакций
