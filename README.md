# Дипломный проект: Обучение языковой модели для предсказания выходов биохимических реакций

Целью проекта было дообучить llm с помощью LoRA для предсказания класса выхода органической реакции, где high - выход >= 70% и low - выход < 70%

## Структура репозитория

Проект состоит из последовательности скриптов и notebook'ов:

1. `1_data_preparation.ipynb` - подготовка и первичная обработка данных, анализ данных, подготовка словаря с уникальными молекулами
2. `2_dict_SMILES_text.py` - создание словаря формата ключ - химическое вещество в формате SMILES, значение - название вещества на английском языке по номенклатуре ИЮПАК
3. `3_data_from_SMILES_to_text.ipynb` - преобразование реакций с SMILES-моелкулами в текстовый формат
4. `4_train_test_splitting.ipynb` - формирование тренировочного и тестового датасетов с включенными few-shot промптами
5. `5_llama_training.py` - обучение модели Reasoning LLaMA v0.1 1B
6. `6_inference.py` - инференс обученной модели
7. `7_metrics.ipynb` - расчет метрик качества модели

На Google-диске лежат все наборы данных (т.к. в GitHub нельзя загружать такие большие файлы), а также продублированный код проекта https://drive.google.com/drive/folders/1aluuIDcfMWWDgcMjaZm31yGXYTW1L38m  

Подробное описание проекта можно найти в документе моего диплома: https://docs.google.com/document/d/18k6BVzBbitiNnUuOjswuUi0GdIbfU60ci3ddHfYMxeM/edit?usp=sharing

Выбор модели (итог - Reasonin Llama v0.1 1B) и формата промпта (итог - few-shots) был осуществлен эксприментально. 20 случайно выбранных реакций из датасета прогонялись через отобранные модели (модели отбирались по новизне и небольшому количесвту параметров), а также прогонялись через лучшие модели с различными формулировками промптов. Результаты экспериментов были записаны в таблицу: https://docs.google.com/spreadsheets/d/1zGEa4tiJ6lQfgJxAZhLvIxbawqEFmnze18G4R2nrink/edit?gid=0#gid=0 

Пример:
![image](https://github.com/user-attachments/assets/73ed615b-3a3e-499f-b3f7-510f5f7ea707)
